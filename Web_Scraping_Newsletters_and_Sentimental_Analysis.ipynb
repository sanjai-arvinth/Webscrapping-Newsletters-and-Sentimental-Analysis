{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "    !pip install requests beautifulsoup4 vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7BuA_CPjA1d",
        "outputId": "1551826c-d0b8-4fb9-dc3b-3bdea714cd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Function to scrape headlines from The Indian Express website using the updated CSS selector\n",
        "def scrape_headlines():\n",
        "    url = \"https://indianexpress.com/\"  # You can replace this with any news website\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to retrieve the webpage\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Scrape the headlines using the updated CSS path\n",
        "    headlines = []\n",
        "    try:\n",
        "        # Use the provided CSS selector for selecting the headline section\n",
        "        headline_elements = soup.select('div#HP_LATEST_NEWS.lead-stories.event-track-class.single_latest_news div.left-part div.other-article')  # Adjusting the selector\n",
        "\n",
        "        for element in headline_elements:\n",
        "            headline = element.get_text(strip=True)\n",
        "            if headline:\n",
        "                headlines.append(headline)\n",
        "    except Exception as e:\n",
        "        print(f\"Error while scraping: {e}\")\n",
        "\n",
        "    return headlines\n",
        "\n",
        "# Function to analyze sentiment of the headlines\n",
        "def analyze_sentiment(headlines):\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    sentiments = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n",
        "\n",
        "    for headline in headlines:\n",
        "        sentiment_score = analyzer.polarity_scores(headline)['compound']\n",
        "\n",
        "        if sentiment_score > 0.05:\n",
        "            sentiments[\"positive\"] += 1\n",
        "        elif sentiment_score < -0.05:\n",
        "            sentiments[\"negative\"] += 1\n",
        "        else:\n",
        "            sentiments[\"neutral\"] += 1\n",
        "\n",
        "    # Calculate overall sentiment\n",
        "    total_headlines = len(headlines)\n",
        "    if total_headlines == 0:\n",
        "        return \"No headlines to analyze\"\n",
        "\n",
        "    positive_percentage = (sentiments[\"positive\"] / total_headlines) * 100\n",
        "    negative_percentage = (sentiments[\"negative\"] / total_headlines) * 100\n",
        "    neutral_percentage = (sentiments[\"neutral\"] / total_headlines) * 100\n",
        "\n",
        "    # Assess overall positivity\n",
        "    if positive_percentage > negative_percentage:\n",
        "        overall_sentiment = \"Overall Positive\"\n",
        "    elif negative_percentage > positive_percentage:\n",
        "        overall_sentiment = \"Overall Negative\"\n",
        "    else:\n",
        "        overall_sentiment = \"Neutral\"\n",
        "\n",
        "    return {\n",
        "        \"sentiment_analysis\": sentiments,\n",
        "        \"overall_sentiment\": overall_sentiment,\n",
        "        \"positive_percentage\": positive_percentage,\n",
        "        \"negative_percentage\": negative_percentage,\n",
        "        \"neutral_percentage\": neutral_percentage\n",
        "    }\n",
        "\n",
        "# Main function to run the scraping and sentiment analysis\n",
        "\n",
        "# Step 1: Scrape headlines from The Indian Express\n",
        "headlines = scrape_headlines()\n",
        "\n",
        "if not headlines:\n",
        "    print(\"No headlines found.\")\n",
        "\n",
        "\n",
        "print(f\"Scraped {len(headlines)} headlines:\")\n",
        "for idx, headline in enumerate(headlines, 1):\n",
        "    print(f\"{idx}. {headline}\")\n",
        "\n",
        "# Step 2: Perform sentiment analysis on the headlines\n",
        "analysis_result = analyze_sentiment(headlines)\n",
        "\n",
        "# Display the sentiment analysis results\n",
        "print(\"\\nSentiment Analysis Results:\")\n",
        "print(f\"Positive Headlines: {analysis_result['sentiment_analysis']['positive']}\")\n",
        "print(f\"Negative Headlines: {analysis_result['sentiment_analysis']['negative']}\")\n",
        "print(f\"Neutral Headlines: {analysis_result['sentiment_analysis']['neutral']}\")\n",
        "print(f\"Overall Sentiment: {analysis_result['overall_sentiment']}\")\n",
        "print(f\"Positive Headlines Percentage: {analysis_result['positive_percentage']:.2f}%\")\n",
        "print(f\"Negative Headlines Percentage: {analysis_result['negative_percentage']:.2f}%\")\n",
        "print(f\"Neutral Headlines Percentage: {analysis_result['neutral_percentage']:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZwMlWmjjBHj",
        "outputId": "c1f95d2e-b450-4c71-9f84-bb0398301978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 15 headlines:\n",
            "1. Express ResearchHow Jawaharlal Nehru wrote the history of India\n",
            "2. ExplainedWhy Bangladesh is rewriting textbooks on 1971 Liberation WarSign In to read\n",
            "3. SC to hear on February 17 Owaisi’s plea seeking implementation of Places of Worship Act\n",
            "4. Express OpinionPicture of a Gurugram farmer beside London Bridge shows aspiration of our timesSubscriber Only\n",
            "5. Watch videoMoment when Tesla Cybertruck burst into flames outside Las Vegas hotel\n",
            "6. 337 mt of toxic waste: The challenge as work begins to clear Bhopal gas tragedy site\n",
            "7. Who’s going to keep their VIP security? VK Singh, Gautam Gambhir among those facing MHA review\n",
            "8. Long ReadsHow Kashmir is curbing heart attack deathsSubscriber Only\n",
            "9. Maharashtra polls done and dusted, calls from both NCP factions for 'reunion'\n",
            "10. Border-Gavaskar TrophyAfter omitting him for Melbourne, India need Gill in must-win 5th Test\n",
            "11. The story of Binodini Dasi, after whom Star Theatre in Kolkata has now been namedSubscriber Only\n",
            "12. 5 great smartphones you SHOULD NOT buy right now\n",
            "13. ‘Won't punish my body and squeeze into someone's idea of fashion’: Tillotama Shome\n",
            "14. Health and WellnessAloo bhujia the most ordered snack for New Year: Why this munchie is adding to your belly fat\n",
            "15. SponsoredHeart Healthy Resolutions for New Year 2025\n",
            "\n",
            "Sentiment Analysis Results:\n",
            "Positive Headlines: 6\n",
            "Negative Headlines: 1\n",
            "Neutral Headlines: 8\n",
            "Overall Sentiment: Overall Positive\n",
            "Positive Headlines Percentage: 40.00%\n",
            "Negative Headlines Percentage: 6.67%\n",
            "Neutral Headlines Percentage: 53.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have 15 headlines, update the categories list to have 15 labels\n",
        "categories = [\n",
        "    \"Technology\", \"Politics\", \"Sports\", \"Business\", \"Entertainment\",\n",
        "    \"Politics\", \"Lifestyle\", \"Sports\", \"Politics\", \"Technology\",\n",
        "    \"Health\", \"Business\", \"Lifestyle\", \"Technology\", \"Entertainment\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "jDudp0QMjEpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "LtBxMVeQvj8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize the headlines\n",
        "tokenizer = Tokenizer(num_words=10000)  # Top 10,000 words\n",
        "tokenizer.fit_on_texts(headlines)\n",
        "X = tokenizer.texts_to_sequences(headlines)\n",
        "\n",
        "# Pad the sequences to ensure all have the same length\n",
        "X_padded = pad_sequences(X, padding='post', maxlen=50)\n",
        "\n",
        "# Label encoding for the categories\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(categories)  # Convert labels to integers\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "-60_1-dPu1yK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}